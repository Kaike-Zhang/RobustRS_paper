## Updated on 2023.07.26
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#RobustnessRS>RobustnessRS</a></li>
    <li><a href=#Robust-ML>Robust ML</a></li>
    <li><a href=#Security-LLM>Security LLM</a></li>
  </ol>
</details>

## RobustnessRS

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2023-07-24**|**Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations: an Empirical Study**|Filippo Betello et.al.|[2307.13165](http://arxiv.org/abs/2307.13165)|null|
|**2023-07-17**|**Evaluating and Enhancing Robustness of Deep Recommendation Systems Against Hardware Errors**|Dongning Ma et.al.|[2307.10244](http://arxiv.org/abs/2307.10244)|**[link](https://github.com/vu-detail/pytei)**|
|**2023-07-17**|**An Admissible Shift-Consistent Method for Recommender Systems**|Tung Nguyen et.al.|[2307.08857](http://arxiv.org/abs/2307.08857)|null|
|**2023-07-17**|**Imposing Consistency Properties on Blackbox Systems with Applications to SVD-Based Recommender Systems**|Tung Nguyen et.al.|[2307.08760](http://arxiv.org/abs/2307.08760)|null|
|**2023-07-06**|**LogitMat : Zeroshot Learning Algorithm for Recommender Systems without Transfer Learning or Pretrained Models**|Hao Wang et.al.|[2307.05680](http://arxiv.org/abs/2307.05680)|null|
|**2023-07-10**|**Causal Neural Graph Collaborative Filtering**|Xiangmeng Wang et.al.|[2307.04384](http://arxiv.org/abs/2307.04384)|null|
|**2023-06-27**|**Shilling Black-box Review-based Recommender Systems through Fake Review Generation**|Hung-Yun Chiang et.al.|[2306.16526](http://arxiv.org/abs/2306.16526)|null|
|**2023-06-28**|**Exploring chemical compound space with a graph-based recommender system**|Elton Ogoshi et.al.|[2306.16496](http://arxiv.org/abs/2306.16496)|**[link](https://github.com/simcomat/ionic-sub-rs)**|
|**2023-06-22**|**Recent Developments in Recommender Systems: A Survey**|Yang Li et.al.|[2306.12680](http://arxiv.org/abs/2306.12680)|null|
|**2023-06-11**|**Securing Visually-Aware Recommender Systems: An Adversarial Image Reconstruction and Detection Framework**|Minglei Yin et.al.|[2306.07992](http://arxiv.org/abs/2306.07992)|null|
|**2023-06-08**|**Safe Collaborative Filtering**|Riku Togashi et.al.|[2306.05292](http://arxiv.org/abs/2306.05292)|**[link](https://github.com/riktor/safer2-recommender)**|
|**2023-05-30**|**Robust Reinforcement Learning Objectives for Sequential Recommender Systems**|Melissa Mozifian et.al.|[2305.18820](http://arxiv.org/abs/2305.18820)|**[link](https://github.com/melfm/sasrec-ccql)**|
|**2023-05-27**|**Choosing the Right Weights: Balancing Value, Strategy, and Noise in Recommender Systems**|Smitha Milli et.al.|[2305.17428](http://arxiv.org/abs/2305.17428)|null|
|**2023-06-19**|**Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding**|Zheng Chen et.al.|[2305.14449](http://arxiv.org/abs/2305.14449)|null|
|**2023-05-23**|**Curse of "Low" Dimensionality in Recommender Systems**|Naoto Ohsaka et.al.|[2305.13597](http://arxiv.org/abs/2305.13597)|null|
|**2023-05-18**|**Preference or Intent? Double Disentangled Collaborative Filtering**|Chao Wang et.al.|[2305.11084](http://arxiv.org/abs/2305.11084)|null|
|**2023-06-10**|**Integrating Item Relevance in Training Loss for Sequential Recommender Systems**|Andrea Bacciu et.al.|[2305.10824](http://arxiv.org/abs/2305.10824)|null|
|**2023-05-03**|**Sim2Rec: A Simulator-based Decision-making Approach to Optimize Real-World Long-term User Engagement in Sequential Recommender Systems**|Xiong-Hui Chen et.al.|[2305.04832](http://arxiv.org/abs/2305.04832)|**[link](https://github.com/xionghuichen/sim2rec)**|
|**2023-07-12**|**Disentangled Contrastive Collaborative Filtering**|Xubin Ren et.al.|[2305.02759](http://arxiv.org/abs/2305.02759)|**[link](https://github.com/hkuds/dccf)**|
|**2023-04-11**|**Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism**|Sohan Salahuddin Mugdho et.al.|[2304.09096](http://arxiv.org/abs/2304.09096)|null|
|**2023-04-15**|**Manipulating Federated Recommender Systems: Poisoning with Synthetic Users and Its Countermeasures**|Wei Yuan et.al.|[2304.03054](http://arxiv.org/abs/2304.03054)|null|
|**2023-03-28**|**Item Graph Convolution Collaborative Filtering for Inductive Recommendations**|Edoardo D'Amico et.al.|[2303.15946](http://arxiv.org/abs/2303.15946)|**[link](https://github.com/damicoedoardo/igccf)**|
|**2023-03-26**|**PORE: Provably Robust Recommender Systems against Data Poisoning Attacks**|Jinyuan Jia et.al.|[2303.14601](http://arxiv.org/abs/2303.14601)|null|
|**2023-03-09**|**Evaluating the Robustness of Conversational Recommender Systems by Adversarial Examples**|Ali Montazeralghaem et.al.|[2303.05575](http://arxiv.org/abs/2303.05575)|null|
|**2023-02-11**|**Regret Guarantees for Adversarial Online Collaborative Filtering**|Stephen Pasteris et.al.|[2302.05765](http://arxiv.org/abs/2302.05765)|null|
|**2023-01-30**|**Interaction-level Membership Inference Attack Against Federated Recommender Systems**|Wei Yuan et.al.|[2301.10964](http://arxiv.org/abs/2301.10964)|null|

<p align=right>(<a href=#Updated-on-20230726>back to top</a>)</p>

## Robust ML

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2023-07-24**|**Adaptive Certified Training: Towards Better Accuracy-Robustness Tradeoffs**|Zhakshylyk Nurlanov et.al.|[2307.13078](http://arxiv.org/abs/2307.13078)|null|
|**2023-07-24**|**Lost In Translation: Generating Adversarial Examples Robust to Round-Trip Translation**|Neel Bhandari et.al.|[2307.12520](http://arxiv.org/abs/2307.12520)|**[link](https://github.com/neelbhandari6/nmt_text_attack)**|
|**2023-07-24**|**Robust Automatic Speech Recognition via WavAugment Guided Phoneme Adversarial Training**|Gege Qi et.al.|[2307.12498](http://arxiv.org/abs/2307.12498)|null|
|**2023-07-21**|**Improving Viewpoint Robustness for Visual Recognition via Adversarial Training**|Shouwei Ruan et.al.|[2307.11528](http://arxiv.org/abs/2307.11528)|null|
|**2023-07-16**|**Byzantine-Robust Distributed Online Learning: Taming Adversarial Participants in An Adversarial Environment**|Xingrong Dong et.al.|[2307.07980](http://arxiv.org/abs/2307.07980)|**[link](https://github.com/wanger521/ogd)**|
|**2023-07-18**|**On the Robustness of Split Learning against Adversarial Attacks**|Mingyuan Fan et.al.|[2307.07916](http://arxiv.org/abs/2307.07916)|null|
|**2023-07-19**|**Why Does Little Robustness Help? Understanding Adversarial Transferability From Surrogate Training**|Yechao Zhang et.al.|[2307.07873](http://arxiv.org/abs/2307.07873)|null|
|**2023-07-20**|**Frequency Domain Adversarial Training for Robust Volumetric Medical Segmentation**|Asif Hanif et.al.|[2307.07269](http://arxiv.org/abs/2307.07269)|**[link](https://github.com/asif-hanif/vafa)**|
|**2023-07-14**|**Certified Robustness for Large Language Models with Self-Denoising**|Zhen Zhang et.al.|[2307.07171](http://arxiv.org/abs/2307.07171)|null|
|**2023-07-10**|**Enhancing Adversarial Robustness via Score-Based Optimization**|Boya Zhang et.al.|[2307.04333](http://arxiv.org/abs/2307.04333)|null|
|**2023-07-07**|**RADAR: Robust AI-Text Detection via Adversarial Learning**|Xiaomeng Hu et.al.|[2307.03838](http://arxiv.org/abs/2307.03838)|null|
|**2023-07-07**|**A Theoretical Perspective on Subnetwork Contributions to Adversarial Robustness**|Jovon Craig et.al.|[2307.03803](http://arxiv.org/abs/2307.03803)|null|
|**2023-07-04**|**Interpretable Computer Vision Models through Adversarial Training: Unveiling the Robustness-Interpretability Connection**|Delyan Boychev et.al.|[2307.02500](http://arxiv.org/abs/2307.02500)|**[link](https://github.com/delyan-boychev/pytorch_trainers_interpretability)**|
|**2023-07-05**|**On the Adversarial Robustness of Generative Autoencoders in the Latent Space**|Mingfei Lu et.al.|[2307.02202](http://arxiv.org/abs/2307.02202)|null|
|**2023-07-04**|**SCAT: Robust Self-supervised Contrastive Learning via Adversarial Training for Text Classification**|Junjie Wu et.al.|[2307.01488](http://arxiv.org/abs/2307.01488)|null|
|**2023-07-03**|**Enhancing the Robustness of QMIX against State-adversarial Attacks**|Weiran Guo et.al.|[2307.00907](http://arxiv.org/abs/2307.00907)|null|
|**2023-07-11**|**Mitigating the Accuracy-Robustness Trade-off via Multi-Teacher Adversarial Distillation**|Shiji Zhao et.al.|[2306.16170](http://arxiv.org/abs/2306.16170)|**[link](https://github.com/zhaoshiji123/mtard-extension)**|
|**2023-07-07**|**Evaluating Similitude and Robustness of Deep Image Denoising Models via Adversarial Attack**|Jie Ning et.al.|[2306.16050](http://arxiv.org/abs/2306.16050)|null|
|**2023-06-27**|**Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning**|Hong Joo Lee et.al.|[2306.15457](http://arxiv.org/abs/2306.15457)|null|
|**2023-06-26**|**Robust and Space-Efficient Dual Adversary Quantum Query Algorithms**|Michael Czekanski et.al.|[2306.15040](http://arxiv.org/abs/2306.15040)|**[link](https://github.com/rtealwitter/quantumqueryoptimizer)**|
|**2023-06-25**|**RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations**|Yilun Zhao et.al.|[2306.14321](http://arxiv.org/abs/2306.14321)|**[link](https://github.com/yilunzhao/robut)**|
|**2023-06-25**|**A Spectral Perspective towards Understanding and Improving Adversarial Robustness**|Binxiao Huang et.al.|[2306.14262](http://arxiv.org/abs/2306.14262)|null|
|**2023-06-25**|**On Evaluating the Adversarial Robustness of Semantic Segmentation Models**|Levente Halmosi et.al.|[2306.14217](http://arxiv.org/abs/2306.14217)|null|
|**2023-06-25**|**Robust Spatiotemporal Traffic Forecasting with Reinforced Dynamic Adversarial Training**|Fan Liu et.al.|[2306.14126](http://arxiv.org/abs/2306.14126)|**[link](https://github.com/usail-hkust/rdat)**|
|**2023-06-23**|**Adversarial Robustness Certification for Bayesian Neural Networks**|Matthew Wicker et.al.|[2306.13614](http://arxiv.org/abs/2306.13614)|**[link](https://github.com/matthewwicker/adversarialrobustnesscertificationforbnns)**|
|**2023-06-22**|**Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models**|Francesco Croce et.al.|[2306.12941](http://arxiv.org/abs/2306.12941)|**[link](https://github.com/nmndeep/robust-segmentation)**|
|**2023-06-22**|**Towards quantum enhanced adversarial robustness in machine learning**|Maxwell T. West et.al.|[2306.12688](http://arxiv.org/abs/2306.12688)|null|
|**2023-06-22**|**RobustNeuralNetworks.jl: a Package for Machine Learning and Data-Driven Control with Certified Robustness**|Nicholas H. Barbara et.al.|[2306.12612](http://arxiv.org/abs/2306.12612)|**[link](https://github.com/acfr/RobustNeuralNetworks.jl)**|
|**2023-06-22**|**Revisiting Image Classifier Training for Improved Certified Robust Defense against Adversarial Patches**|Aniruddha Saha et.al.|[2306.12610](http://arxiv.org/abs/2306.12610)|null|
|**2023-07-03**|**Evaluating the Adversarial Robustness of Convolution-based Human Motion Prediction**|Chengxu Duan et.al.|[2306.11990](http://arxiv.org/abs/2306.11990)|**[link](https://github.com/chengxuduan/advhmp)**|
|**2023-06-20**|**Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy**|Ioana Ciucă et.al.|[2306.11648](http://arxiv.org/abs/2306.11648)|null|
|**2023-06-21**|**Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding**|Venkata Prabhakara Sarath Nookala et.al.|[2306.11066](http://arxiv.org/abs/2306.11066)|**[link](https://github.com/claws-lab/few-shot-adversarial-robustness)**|

<p align=right>(<a href=#Updated-on-20230726>back to top</a>)</p>

## Security LLM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2023-07-17**|**Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models**|Huachuan Qiu et.al.|[2307.08487](http://arxiv.org/abs/2307.08487)|**[link](https://github.com/qiuhuachuan/latent-jailbreak)**|
|**2023-07-15**|**Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text**|Zhun Yang et.al.|[2307.07696](http://arxiv.org/abs/2307.07696)|**[link](https://github.com/azreasoners/llm-asp)**|
|**2023-07-14**|**Certified Robustness for Large Language Models with Self-Denoising**|Zhen Zhang et.al.|[2307.07171](http://arxiv.org/abs/2307.07171)|null|
|**2023-06-26**|**Exploring the Robustness of Large Language Models for Solving Programming Problems**|Atsushi Shirafuji et.al.|[2306.14583](http://arxiv.org/abs/2306.14583)|null|
|**2023-06-20**|**Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy**|Ioana Ciucă et.al.|[2306.11648](http://arxiv.org/abs/2306.11648)|null|
|**2023-06-07**|**Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations**|Lifan Yuan et.al.|[2306.04618](http://arxiv.org/abs/2306.04618)|**[link](https://github.com/lifan-yuan/ood_nlp)**|
|**2023-06-13**|**PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts**|Kaijie Zhu et.al.|[2306.04528](http://arxiv.org/abs/2306.04528)|**[link](https://github.com/microsoft/promptbench)**|
|**2023-05-23**|**Are Large Language Models Robust Zero-shot Coreference Resolvers?**|Nghia T. Le et.al.|[2305.14489](http://arxiv.org/abs/2305.14489)|null|
|**2023-06-19**|**Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding**|Zheng Chen et.al.|[2305.14449](http://arxiv.org/abs/2305.14449)|null|
|**2023-05-23**|**Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models**|Afra Amini et.al.|[2305.14171](http://arxiv.org/abs/2305.14171)|null|
|**2023-05-23**|**Robust Instruction Optimization for Large Language Models with Distribution Shifts**|Moxin Li et.al.|[2305.13954](http://arxiv.org/abs/2305.13954)|null|
|**2023-05-18**|**Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs**|Giorgi Kokaia et.al.|[2305.11334](http://arxiv.org/abs/2305.11334)|null|
|**2023-05-25**|**Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility**|Wentao Ye et.al.|[2305.10235](http://arxiv.org/abs/2305.10235)|null|
|**2023-06-08**|**Sensitivity and Robustness of Large Language Models to Prompt Template in Japanese Text Classification Tasks**|Chengguang Gan et.al.|[2305.08714](http://arxiv.org/abs/2305.08714)|null|
|**2023-04-05**|**Behavioral estimates of conceptual structure are robust across tasks in humans but not large language models**|Siddharth Suresh et.al.|[2304.02754](http://arxiv.org/abs/2304.02754)|null|
|**2022-05-11**|**Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks**|Katherine M. Collins et.al.|[2205.05718](http://arxiv.org/abs/2205.05718)|**[link](https://github.com/collinskatie/structured_flexible_and_robust)**|

<p align=right>(<a href=#Updated-on-20230726>back to top</a>)</p>

