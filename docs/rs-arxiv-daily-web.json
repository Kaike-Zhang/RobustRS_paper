{"RobustnessRS": {"2306.16496": "|**2023-06-28**|**Exploring chemical compound space with a graph-based recommender system**|Elton Ogoshi et.al.|[2306.16496](http://arxiv.org/abs/2306.16496)|**[link](https://github.com/simcomat/ionic-sub-rs)**|\n", "2306.16526": "|**2023-06-27**|**Shilling Black-box Review-based Recommender Systems through Fake Review Generation**|Hung-Yun Chiang et.al.|[2306.16526](http://arxiv.org/abs/2306.16526)|null|\n", "2306.12680": "|**2023-06-22**|**Recent Developments in Recommender Systems: A Survey**|Yang Li et.al.|[2306.12680](http://arxiv.org/abs/2306.12680)|null|\n", "2306.07992": "|**2023-06-11**|**Securing Visually-Aware Recommender Systems: An Adversarial Image Reconstruction and Detection Framework**|Minglei Yin et.al.|[2306.07992](http://arxiv.org/abs/2306.07992)|null|\n", "2306.05292": "|**2023-06-08**|**Safe Collaborative Filtering**|Riku Togashi et.al.|[2306.05292](http://arxiv.org/abs/2306.05292)|**[link](https://github.com/riktor/safer2-recommender)**|\n", "2305.18820": "|**2023-05-30**|**Robust Reinforcement Learning Objectives for Sequential Recommender Systems**|Melissa Mozifian et.al.|[2305.18820](http://arxiv.org/abs/2305.18820)|**[link](https://github.com/melfm/sasrec-ccql)**|\n", "2305.17428": "|**2023-05-27**|**Choosing the Right Weights: Balancing Value, Strategy, and Noise in Recommender Systems**|Smitha Milli et.al.|[2305.17428](http://arxiv.org/abs/2305.17428)|null|\n", "2305.14449": "|**2023-06-19**|**Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding**|Zheng Chen et.al.|[2305.14449](http://arxiv.org/abs/2305.14449)|null|\n", "2305.13597": "|**2023-05-23**|**Curse of \"Low\" Dimensionality in Recommender Systems**|Naoto Ohsaka et.al.|[2305.13597](http://arxiv.org/abs/2305.13597)|null|\n", "2305.11084": "|**2023-05-18**|**Preference or Intent? Double Disentangled Collaborative Filtering**|Chao Wang et.al.|[2305.11084](http://arxiv.org/abs/2305.11084)|null|\n", "2305.10824": "|**2023-06-10**|**Integrating Item Relevance in Training Loss for Sequential Recommender Systems**|Andrea Bacciu et.al.|[2305.10824](http://arxiv.org/abs/2305.10824)|null|\n", "2305.02759": "|**2023-07-12**|**Disentangled Contrastive Collaborative Filtering**|Xubin Ren et.al.|[2305.02759](http://arxiv.org/abs/2305.02759)|**[link](https://github.com/hkuds/dccf)**|\n", "2305.04832": "|**2023-05-03**|**Sim2Rec: A Simulator-based Decision-making Approach to Optimize Real-World Long-term User Engagement in Sequential Recommender Systems**|Xiong-Hui Chen et.al.|[2305.04832](http://arxiv.org/abs/2305.04832)|**[link](https://github.com/xionghuichen/sim2rec)**|\n", "2304.09096": "|**2023-04-11**|**Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism**|Sohan Salahuddin Mugdho et.al.|[2304.09096](http://arxiv.org/abs/2304.09096)|null|\n", "2304.03054": "|**2023-04-15**|**Manipulating Federated Recommender Systems: Poisoning with Synthetic Users and Its Countermeasures**|Wei Yuan et.al.|[2304.03054](http://arxiv.org/abs/2304.03054)|null|\n", "2303.15946": "|**2023-03-28**|**Item Graph Convolution Collaborative Filtering for Inductive Recommendations**|Edoardo D'Amico et.al.|[2303.15946](http://arxiv.org/abs/2303.15946)|**[link](https://github.com/damicoedoardo/igccf)**|\n", "2303.14601": "|**2023-03-26**|**PORE: Provably Robust Recommender Systems against Data Poisoning Attacks**|Jinyuan Jia et.al.|[2303.14601](http://arxiv.org/abs/2303.14601)|null|\n", "2303.05575": "|**2023-03-09**|**Evaluating the Robustness of Conversational Recommender Systems by Adversarial Examples**|Ali Montazeralghaem et.al.|[2303.05575](http://arxiv.org/abs/2303.05575)|null|\n", "2302.05765": "|**2023-02-11**|**Regret Guarantees for Adversarial Online Collaborative Filtering**|Stephen Pasteris et.al.|[2302.05765](http://arxiv.org/abs/2302.05765)|null|\n", "2301.10964": "|**2023-01-30**|**Interaction-level Membership Inference Attack Against Federated Recommender Systems**|Wei Yuan et.al.|[2301.10964](http://arxiv.org/abs/2301.10964)|null|\n", "2307.04384": "|**2023-07-10**|**Causal Neural Graph Collaborative Filtering**|Xiangmeng Wang et.al.|[2307.04384](http://arxiv.org/abs/2307.04384)|null|\n", "2307.05680": "|**2023-07-06**|**LogitMat : Zeroshot Learning Algorithm for Recommender Systems without Transfer Learning or Pretrained Models**|Hao Wang et.al.|[2307.05680](http://arxiv.org/abs/2307.05680)|null|\n", "2307.08857": "|**2023-07-17**|**An Admissible Shift-Consistent Method for Recommender Systems**|Tung Nguyen et.al.|[2307.08857](http://arxiv.org/abs/2307.08857)|null|\n", "2307.08760": "|**2023-07-17**|**Imposing Consistency Properties on Blackbox Systems with Applications to SVD-Based Recommender Systems**|Tung Nguyen et.al.|[2307.08760](http://arxiv.org/abs/2307.08760)|null|\n", "2307.10244": "|**2023-07-17**|**Evaluating and Enhancing Robustness of Deep Recommendation Systems Against Hardware Errors**|Dongning Ma et.al.|[2307.10244](http://arxiv.org/abs/2307.10244)|**[link](https://github.com/vu-detail/pytei)**|\n", "2307.13165": "|**2023-07-24**|**Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations: an Empirical Study**|Filippo Betello et.al.|[2307.13165](http://arxiv.org/abs/2307.13165)|null|\n"}, "Robust ML": {"2307.02202": "|**2023-07-05**|**On the Adversarial Robustness of Generative Autoencoders in the Latent Space**|Mingfei Lu et.al.|[2307.02202](http://arxiv.org/abs/2307.02202)|null|\n", "2307.02500": "|**2023-07-04**|**Interpretable Computer Vision Models through Adversarial Training: Unveiling the Robustness-Interpretability Connection**|Delyan Boychev et.al.|[2307.02500](http://arxiv.org/abs/2307.02500)|**[link](https://github.com/delyan-boychev/pytorch_trainers_interpretability)**|\n", "2307.01488": "|**2023-07-04**|**SCAT: Robust Self-supervised Contrastive Learning via Adversarial Training for Text Classification**|Junjie Wu et.al.|[2307.01488](http://arxiv.org/abs/2307.01488)|null|\n", "2307.00907": "|**2023-07-03**|**Enhancing the Robustness of QMIX against State-adversarial Attacks**|Weiran Guo et.al.|[2307.00907](http://arxiv.org/abs/2307.00907)|null|\n", "2306.16170": "|**2023-07-11**|**Mitigating the Accuracy-Robustness Trade-off via Multi-Teacher Adversarial Distillation**|Shiji Zhao et.al.|[2306.16170](http://arxiv.org/abs/2306.16170)|**[link](https://github.com/zhaoshiji123/mtard-extension)**|\n", "2306.16050": "|**2023-07-07**|**Evaluating Similitude and Robustness of Deep Image Denoising Models via Adversarial Attack**|Jie Ning et.al.|[2306.16050](http://arxiv.org/abs/2306.16050)|null|\n", "2306.15457": "|**2023-06-27**|**Robust Proxy: Improving Adversarial Robustness by Robust Proxy Learning**|Hong Joo Lee et.al.|[2306.15457](http://arxiv.org/abs/2306.15457)|null|\n", "2306.15040": "|**2023-06-26**|**Robust and Space-Efficient Dual Adversary Quantum Query Algorithms**|Michael Czekanski et.al.|[2306.15040](http://arxiv.org/abs/2306.15040)|**[link](https://github.com/rtealwitter/quantumqueryoptimizer)**|\n", "2306.14321": "|**2023-06-25**|**RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations**|Yilun Zhao et.al.|[2306.14321](http://arxiv.org/abs/2306.14321)|**[link](https://github.com/yilunzhao/robut)**|\n", "2306.14262": "|**2023-06-25**|**A Spectral Perspective towards Understanding and Improving Adversarial Robustness**|Binxiao Huang et.al.|[2306.14262](http://arxiv.org/abs/2306.14262)|null|\n", "2306.14217": "|**2023-06-25**|**On Evaluating the Adversarial Robustness of Semantic Segmentation Models**|Levente Halmosi et.al.|[2306.14217](http://arxiv.org/abs/2306.14217)|null|\n", "2306.14126": "|**2023-06-25**|**Robust Spatiotemporal Traffic Forecasting with Reinforced Dynamic Adversarial Training**|Fan Liu et.al.|[2306.14126](http://arxiv.org/abs/2306.14126)|**[link](https://github.com/usail-hkust/rdat)**|\n", "2306.13614": "|**2023-06-23**|**Adversarial Robustness Certification for Bayesian Neural Networks**|Matthew Wicker et.al.|[2306.13614](http://arxiv.org/abs/2306.13614)|**[link](https://github.com/matthewwicker/adversarialrobustnesscertificationforbnns)**|\n", "2306.12941": "|**2023-06-22**|**Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models**|Francesco Croce et.al.|[2306.12941](http://arxiv.org/abs/2306.12941)|**[link](https://github.com/nmndeep/robust-segmentation)**|\n", "2306.12688": "|**2023-06-22**|**Towards quantum enhanced adversarial robustness in machine learning**|Maxwell T. West et.al.|[2306.12688](http://arxiv.org/abs/2306.12688)|null|\n", "2306.12612": "|**2023-06-22**|**RobustNeuralNetworks.jl: a Package for Machine Learning and Data-Driven Control with Certified Robustness**|Nicholas H. Barbara et.al.|[2306.12612](http://arxiv.org/abs/2306.12612)|**[link](https://github.com/acfr/RobustNeuralNetworks.jl)**|\n", "2306.12610": "|**2023-06-22**|**Revisiting Image Classifier Training for Improved Certified Robust Defense against Adversarial Patches**|Aniruddha Saha et.al.|[2306.12610](http://arxiv.org/abs/2306.12610)|null|\n", "2306.11990": "|**2023-07-03**|**Evaluating the Adversarial Robustness of Convolution-based Human Motion Prediction**|Chengxu Duan et.al.|[2306.11990](http://arxiv.org/abs/2306.11990)|**[link](https://github.com/chengxuduan/advhmp)**|\n", "2306.11648": "|**2023-06-20**|**Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy**|Ioana Ciuc\u0103 et.al.|[2306.11648](http://arxiv.org/abs/2306.11648)|null|\n", "2306.11066": "|**2023-06-21**|**Adversarial Robustness of Prompt-based Few-Shot Learning for Natural Language Understanding**|Venkata Prabhakara Sarath Nookala et.al.|[2306.11066](http://arxiv.org/abs/2306.11066)|**[link](https://github.com/claws-lab/few-shot-adversarial-robustness)**|\n", "2307.04333": "|**2023-07-10**|**Enhancing Adversarial Robustness via Score-Based Optimization**|Boya Zhang et.al.|[2307.04333](http://arxiv.org/abs/2307.04333)|null|\n", "2307.03838": "|**2023-07-07**|**RADAR: Robust AI-Text Detection via Adversarial Learning**|Xiaomeng Hu et.al.|[2307.03838](http://arxiv.org/abs/2307.03838)|null|\n", "2307.03803": "|**2023-07-07**|**A Theoretical Perspective on Subnetwork Contributions to Adversarial Robustness**|Jovon Craig et.al.|[2307.03803](http://arxiv.org/abs/2307.03803)|null|\n", "2307.07269": "|**2023-07-20**|**Frequency Domain Adversarial Training for Robust Volumetric Medical Segmentation**|Asif Hanif et.al.|[2307.07269](http://arxiv.org/abs/2307.07269)|**[link](https://github.com/asif-hanif/vafa)**|\n", "2307.07171": "|**2023-07-14**|**Certified Robustness for Large Language Models with Self-Denoising**|Zhen Zhang et.al.|[2307.07171](http://arxiv.org/abs/2307.07171)|null|\n", "2307.07980": "|**2023-07-16**|**Byzantine-Robust Distributed Online Learning: Taming Adversarial Participants in An Adversarial Environment**|Xingrong Dong et.al.|[2307.07980](http://arxiv.org/abs/2307.07980)|**[link](https://github.com/wanger521/ogd)**|\n", "2307.07916": "|**2023-07-18**|**On the Robustness of Split Learning against Adversarial Attacks**|Mingyuan Fan et.al.|[2307.07916](http://arxiv.org/abs/2307.07916)|null|\n", "2307.07873": "|**2023-08-08**|**Why Does Little Robustness Help? Understanding Adversarial Transferability From Surrogate Training**|Yechao Zhang et.al.|[2307.07873](http://arxiv.org/abs/2307.07873)|null|\n", "2307.11528": "|**2023-07-21**|**Improving Viewpoint Robustness for Visual Recognition via Adversarial Training**|Shouwei Ruan et.al.|[2307.11528](http://arxiv.org/abs/2307.11528)|null|\n", "2307.12520": "|**2023-07-24**|**Lost In Translation: Generating Adversarial Examples Robust to Round-Trip Translation**|Neel Bhandari et.al.|[2307.12520](http://arxiv.org/abs/2307.12520)|**[link](https://github.com/neelbhandari6/nmt_text_attack)**|\n", "2307.12498": "|**2023-07-24**|**Robust Automatic Speech Recognition via WavAugment Guided Phoneme Adversarial Training**|Gege Qi et.al.|[2307.12498](http://arxiv.org/abs/2307.12498)|null|\n", "2307.13078": "|**2023-07-24**|**Adaptive Certified Training: Towards Better Accuracy-Robustness Tradeoffs**|Zhakshylyk Nurlanov et.al.|[2307.13078](http://arxiv.org/abs/2307.13078)|null|\n", "2307.15157": "|**2023-07-31**|**R-LPIPS: An Adversarially Robust Perceptual Similarity Metric**|Sara Ghazanfari et.al.|[2307.15157](http://arxiv.org/abs/2307.15157)|**[link](https://github.com/saraghazanfari/r-lpips)**|\n", "2307.16630": "|**2023-07-31**|**Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks**|Xinyu Zhang et.al.|[2307.16630](http://arxiv.org/abs/2307.16630)|null|\n", "2307.16361": "|**2023-07-31**|**Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples**|Qiufan Ji et.al.|[2307.16361](http://arxiv.org/abs/2307.16361)|**[link](https://github.com/qiufan319/benchmark_pc_attack)**|\n", "2308.00346": "|**2023-08-01**|**Dynamic ensemble selection based on Deep Neural Network Uncertainty Estimation for Adversarial Robustness**|Ruoxi Qin et.al.|[2308.00346](http://arxiv.org/abs/2308.00346)|null|\n", "2308.00311": "|**2023-08-01**|**Doubly Robust Instance-Reweighted Adversarial Training**|Daouda Sow et.al.|[2308.00311](http://arxiv.org/abs/2308.00311)|null|\n", "2308.00165": "|**2023-07-31**|**Adversarially Robust Neural Legal Judgement Systems**|Rohit Raj et.al.|[2308.00165](http://arxiv.org/abs/2308.00165)|null|\n", "2308.00854": "|**2023-08-01**|**Training on Foveated Images Improves Robustness to Adversarial Attacks**|Muhammad A. Shah et.al.|[2308.00854](http://arxiv.org/abs/2308.00854)|null|\n", "2308.01823": "|**2023-08-03**|**Hard Adversarial Example Mining for Improving Robust Fairness**|Chenhao Lin et.al.|[2308.01823](http://arxiv.org/abs/2308.01823)|null|\n", "2308.02116": "|**2023-08-04**|**AdvFAS: A robust face anti-spoofing framework against adversarial examples**|Jiawei Chen et.al.|[2308.02116](http://arxiv.org/abs/2308.02116)|null|\n", "2308.03476": "|**2023-08-07**|**Exploring the Physical World Adversarial Robustness of Vehicle Detection**|Wei Jiang et.al.|[2308.03476](http://arxiv.org/abs/2308.03476)|null|\n", "2308.02533": "|**2023-08-01**|**Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning**|Kaijie Zhu et.al.|[2308.02533](http://arxiv.org/abs/2308.02533)|null|\n"}, "Security LLM": {"2306.14583": "|**2023-06-26**|**Exploring the Robustness of Large Language Models for Solving Programming Problems**|Atsushi Shirafuji et.al.|[2306.14583](http://arxiv.org/abs/2306.14583)|null|\n", "2306.11648": "|**2023-06-20**|**Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy**|Ioana Ciuc\u0103 et.al.|[2306.11648](http://arxiv.org/abs/2306.11648)|null|\n", "2306.04618": "|**2023-06-07**|**Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations**|Lifan Yuan et.al.|[2306.04618](http://arxiv.org/abs/2306.04618)|**[link](https://github.com/lifan-yuan/ood_nlp)**|\n", "2306.04528": "|**2023-06-13**|**PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts**|Kaijie Zhu et.al.|[2306.04528](http://arxiv.org/abs/2306.04528)|**[link](https://github.com/microsoft/promptbench)**|\n", "2305.14489": "|**2023-05-23**|**Are Large Language Models Robust Zero-shot Coreference Resolvers?**|Nghia T. Le et.al.|[2305.14489](http://arxiv.org/abs/2305.14489)|null|\n", "2305.14449": "|**2023-06-19**|**Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding**|Zheng Chen et.al.|[2305.14449](http://arxiv.org/abs/2305.14449)|null|\n", "2305.14171": "|**2023-05-23**|**Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models**|Afra Amini et.al.|[2305.14171](http://arxiv.org/abs/2305.14171)|null|\n", "2305.13954": "|**2023-05-23**|**Robust Instruction Optimization for Large Language Models with Distribution Shifts**|Moxin Li et.al.|[2305.13954](http://arxiv.org/abs/2305.13954)|null|\n", "2305.11334": "|**2023-05-18**|**Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs**|Giorgi Kokaia et.al.|[2305.11334](http://arxiv.org/abs/2305.11334)|null|\n", "2305.10235": "|**2023-05-25**|**Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility**|Wentao Ye et.al.|[2305.10235](http://arxiv.org/abs/2305.10235)|null|\n", "2305.08714": "|**2023-06-08**|**Sensitivity and Robustness of Large Language Models to Prompt Template in Japanese Text Classification Tasks**|Chengguang Gan et.al.|[2305.08714](http://arxiv.org/abs/2305.08714)|null|\n", "2304.02754": "|**2023-04-05**|**Behavioral estimates of conceptual structure are robust across tasks in humans but not large language models**|Siddharth Suresh et.al.|[2304.02754](http://arxiv.org/abs/2304.02754)|null|\n", "2205.05718": "|**2022-05-11**|**Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks**|Katherine M. Collins et.al.|[2205.05718](http://arxiv.org/abs/2205.05718)|**[link](https://github.com/collinskatie/structured_flexible_and_robust)**|\n", "2307.07171": "|**2023-07-14**|**Certified Robustness for Large Language Models with Self-Denoising**|Zhen Zhang et.al.|[2307.07171](http://arxiv.org/abs/2307.07171)|null|\n", "2307.08487": "|**2023-07-17**|**Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models**|Huachuan Qiu et.al.|[2307.08487](http://arxiv.org/abs/2307.08487)|**[link](https://github.com/qiuhuachuan/latent-jailbreak)**|\n", "2307.07696": "|**2023-07-15**|**Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text**|Zhun Yang et.al.|[2307.07696](http://arxiv.org/abs/2307.07696)|**[link](https://github.com/azreasoners/llm-asp)**|\n"}}